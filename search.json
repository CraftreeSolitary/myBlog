[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Devansh’s Blog",
    "section": "",
    "text": "Have you ever questioned what’s real? In the world of Artificial Intelligence and Machine Learning, the lines can get blurry. This blog explores the fascinating world of AI and ML, peeling back the layers and revealing the code behind the magic.",
    "crumbs": [
      "About Me"
    ]
  },
  {
    "objectID": "index.html#hi",
    "href": "index.html#hi",
    "title": "Devansh’s Blog",
    "section": "",
    "text": "Have you ever questioned what’s real? In the world of Artificial Intelligence and Machine Learning, the lines can get blurry. This blog explores the fascinating world of AI and ML, peeling back the layers and revealing the code behind the magic.",
    "crumbs": [
      "About Me"
    ]
  },
  {
    "objectID": "animal-classifier-ML.html",
    "href": "animal-classifier-ML.html",
    "title": "Animal Classifier",
    "section": "",
    "text": "In this code cell, I first configure the environment to download a specific dataset from Kaggle for further analysis in my Quarto blog. I define the target dataset using the competition_name variable and specify the path to a local file containing my Kaggle API credentials (kaggle_creds_path). To interact with the Kaggle platform, I install the required kaggle library using pip. Since this code will be embedded in a Quarto blog, I leverage the notebook execution syntax (!) to perform certain actions. Following that, I ensure proper credential storage by creating a hidden directory (~/.kaggle) in the user’s home directory and securely copying the credentials file there. Finally, I initiate the download of the animal image dataset using the Kaggle library and create a directory (kaggle_data) to store the downloaded data.\ncompetition_name = \"iamsouravbanerjee/animal-image-dataset-90-different-animals\"\n\nkaggle_creds_path = \"./kaggle.json\"\n\n! pip install kaggle --quiet\n\n\n! mkdir ~/.kaggle\n! cp /content/kaggle.json ~/.kaggle/\n! chmod 600 ~/.kaggle/kaggle.json\n\n! kaggle datasets download -d {competition_name}\n\n! mkdir kaggle_data\n! unzip animal-image-dataset-90-different-animals.zip -d kaggle_data\nLeveraging os and shutil, I define paths for the original and desired structures. First, I create the main directory (onevrest) to house the reorganized data. A special folder (badger) is then copied entirely using shutil.copytree. For remaining folders, a target directory (f2) is created. I iterate through the original data, excluding the special folder. Individual files within valid folders are copied to f2 using shutil.copy2.\nimport os\nimport shutil\n\noriginal_parent_dir = \"./kaggle_data/animals/animals\"\nnew_parent_dir = \"./onevrest\"\ntarget_folder = \"f2\"\nspecial_folder = \"badger\"\n\nos.makedirs(new_parent_dir, exist_ok=True)\n\n# Copy the special folder as-is\nshutil.copytree(os.path.join(original_parent_dir, special_folder),\n                os.path.join(new_parent_dir, special_folder))\n\n# Process the other folders efficiently\ntarget_dir = os.path.join(new_parent_dir, target_folder)\nos.makedirs(target_dir, exist_ok=True)\n\nfor dir in os.listdir(original_parent_dir):\n    dir_path = os.path.join(original_parent_dir, dir)\n    if os.path.isdir(dir_path) and dir != special_folder:\n        for file in os.listdir(dir_path):\n            file_src = os.path.join(dir_path, file)\n            file_dest = os.path.join(target_dir, file)\n            shutil.copy2(file_src, file_dest)\n\n        # Do NOT remove the source directories\nIn this code block, we tackle the reorganization of the downloaded animal image dataset. We rely on Python’s os and shutil modules for file system operations. First, we establish paths for both the original data’s structure (original_parent_dir) and the desired new directory layout (new_parent_dir) with five subfolders (d1 to d5). We ensure the existence of new_parent_dir to avoid errors. To effectively distribute the original 90 folders, we create a sorted list and calculate the number of folders each subfolder in the new structure should hold (folders_per_group). A handy copy_files function is defined to efficiently move files between directories. The core logic involves iterating through the original folders. For each one, we calculate the corresponding destination subfolder (d1 to d5) based on the iteration index. We then construct the new folder’s path dynamically and copy the contents of the current folder using our copy_files function.\nimport os\nimport shutil\n\n# Original parent directory containing the 90 folders\noriginal_parent_dir = \"/kaggle/input/animal-image-dataset-90-different-animals/animals/animals\"\n\n# New parent directory where the 5 folders (d1 to d5) will be created\nnew_parent_dir = \"./fiveclass\"\n\n# Make sure the new parent directory exists\nos.makedirs(new_parent_dir, exist_ok=True)\n\n# Get a sorted list of all folders in the original parent directory\n# Assuming folder names allow them to be correctly sorted to reflect the desired order\nfolders = sorted([f for f in os.listdir(original_parent_dir) if os.path.isdir(os.path.join(original_parent_dir, f))])\n\n# Calculate the number of folders to distribute into each of the 5 new folders\nfolders_per_group = len(folders) // 5\n\n# Function to copy files from source to destination\ndef copy_files(src_dir, dest_dir):\n    os.makedirs(dest_dir, exist_ok=True)\n    for file in os.listdir(src_dir):\n        shutil.copy2(os.path.join(src_dir, file), os.path.join(dest_dir, file))\n\n# Iterate through each of the original folders and copy its contents to the correct new folder\nfor i, folder in enumerate(folders):\n    # Determine the index for the new folder (d1 to d5)\n    new_folder_index = i // folders_per_group + 1\n    if new_folder_index &gt; 5:  # Ensure we don't go beyond d5\n        new_folder_index = 5\n\n    # Construct the new folder name and path\n    new_folder_name = f\"d{new_folder_index}\"\n    new_folder_path = os.path.join(new_parent_dir, new_folder_name)\n\n    # Copy the contents of the current folder to the new folder\n    current_folder_path = os.path.join(original_parent_dir, folder)\n    copy_files(current_folder_path, new_folder_path)",
    "crumbs": [
      "Animal Classifier"
    ]
  },
  {
    "objectID": "animal-classifier-ML.html#getting-the-dataset-and-organizing-folders",
    "href": "animal-classifier-ML.html#getting-the-dataset-and-organizing-folders",
    "title": "Animal Classifier",
    "section": "",
    "text": "In this code cell, I first configure the environment to download a specific dataset from Kaggle for further analysis in my Quarto blog. I define the target dataset using the competition_name variable and specify the path to a local file containing my Kaggle API credentials (kaggle_creds_path). To interact with the Kaggle platform, I install the required kaggle library using pip. Since this code will be embedded in a Quarto blog, I leverage the notebook execution syntax (!) to perform certain actions. Following that, I ensure proper credential storage by creating a hidden directory (~/.kaggle) in the user’s home directory and securely copying the credentials file there. Finally, I initiate the download of the animal image dataset using the Kaggle library and create a directory (kaggle_data) to store the downloaded data.\ncompetition_name = \"iamsouravbanerjee/animal-image-dataset-90-different-animals\"\n\nkaggle_creds_path = \"./kaggle.json\"\n\n! pip install kaggle --quiet\n\n\n! mkdir ~/.kaggle\n! cp /content/kaggle.json ~/.kaggle/\n! chmod 600 ~/.kaggle/kaggle.json\n\n! kaggle datasets download -d {competition_name}\n\n! mkdir kaggle_data\n! unzip animal-image-dataset-90-different-animals.zip -d kaggle_data\nLeveraging os and shutil, I define paths for the original and desired structures. First, I create the main directory (onevrest) to house the reorganized data. A special folder (badger) is then copied entirely using shutil.copytree. For remaining folders, a target directory (f2) is created. I iterate through the original data, excluding the special folder. Individual files within valid folders are copied to f2 using shutil.copy2.\nimport os\nimport shutil\n\noriginal_parent_dir = \"./kaggle_data/animals/animals\"\nnew_parent_dir = \"./onevrest\"\ntarget_folder = \"f2\"\nspecial_folder = \"badger\"\n\nos.makedirs(new_parent_dir, exist_ok=True)\n\n# Copy the special folder as-is\nshutil.copytree(os.path.join(original_parent_dir, special_folder),\n                os.path.join(new_parent_dir, special_folder))\n\n# Process the other folders efficiently\ntarget_dir = os.path.join(new_parent_dir, target_folder)\nos.makedirs(target_dir, exist_ok=True)\n\nfor dir in os.listdir(original_parent_dir):\n    dir_path = os.path.join(original_parent_dir, dir)\n    if os.path.isdir(dir_path) and dir != special_folder:\n        for file in os.listdir(dir_path):\n            file_src = os.path.join(dir_path, file)\n            file_dest = os.path.join(target_dir, file)\n            shutil.copy2(file_src, file_dest)\n\n        # Do NOT remove the source directories\nIn this code block, we tackle the reorganization of the downloaded animal image dataset. We rely on Python’s os and shutil modules for file system operations. First, we establish paths for both the original data’s structure (original_parent_dir) and the desired new directory layout (new_parent_dir) with five subfolders (d1 to d5). We ensure the existence of new_parent_dir to avoid errors. To effectively distribute the original 90 folders, we create a sorted list and calculate the number of folders each subfolder in the new structure should hold (folders_per_group). A handy copy_files function is defined to efficiently move files between directories. The core logic involves iterating through the original folders. For each one, we calculate the corresponding destination subfolder (d1 to d5) based on the iteration index. We then construct the new folder’s path dynamically and copy the contents of the current folder using our copy_files function.\nimport os\nimport shutil\n\n# Original parent directory containing the 90 folders\noriginal_parent_dir = \"/kaggle/input/animal-image-dataset-90-different-animals/animals/animals\"\n\n# New parent directory where the 5 folders (d1 to d5) will be created\nnew_parent_dir = \"./fiveclass\"\n\n# Make sure the new parent directory exists\nos.makedirs(new_parent_dir, exist_ok=True)\n\n# Get a sorted list of all folders in the original parent directory\n# Assuming folder names allow them to be correctly sorted to reflect the desired order\nfolders = sorted([f for f in os.listdir(original_parent_dir) if os.path.isdir(os.path.join(original_parent_dir, f))])\n\n# Calculate the number of folders to distribute into each of the 5 new folders\nfolders_per_group = len(folders) // 5\n\n# Function to copy files from source to destination\ndef copy_files(src_dir, dest_dir):\n    os.makedirs(dest_dir, exist_ok=True)\n    for file in os.listdir(src_dir):\n        shutil.copy2(os.path.join(src_dir, file), os.path.join(dest_dir, file))\n\n# Iterate through each of the original folders and copy its contents to the correct new folder\nfor i, folder in enumerate(folders):\n    # Determine the index for the new folder (d1 to d5)\n    new_folder_index = i // folders_per_group + 1\n    if new_folder_index &gt; 5:  # Ensure we don't go beyond d5\n        new_folder_index = 5\n\n    # Construct the new folder name and path\n    new_folder_name = f\"d{new_folder_index}\"\n    new_folder_path = os.path.join(new_parent_dir, new_folder_name)\n\n    # Copy the contents of the current folder to the new folder\n    current_folder_path = os.path.join(original_parent_dir, folder)\n    copy_files(current_folder_path, new_folder_path)",
    "crumbs": [
      "Animal Classifier"
    ]
  },
  {
    "objectID": "animal-classifier-ML.html#binary-classification",
    "href": "animal-classifier-ML.html#binary-classification",
    "title": "Animal Classifier",
    "section": "Binary Classification",
    "text": "Binary Classification\nThis code lays the foundation for training an image classifier using a technique called K-fold cross-validation. First, it imports necessary libraries for deep learning with PyTorch, data manipulation, and K-fold functionality from scikit-learn. Next, it defines a series of transformations to be applied to the images during training. These transformations resize, randomly flip, convert to tensors, and normalize the pixel values. The code then establishes pointers to two folders likely containing the training data (data_dir and data_dir2). Finally, it sets up K-fold cross-validation using scikit-learn. The KFold object will split the data into three parts (folds) for training and validation, ensuring a more robust evaluation of the machine learning model’s performance.\nimport os\nimport torch\nimport torchvision.transforms as transforms\nfrom torchvision import datasets, models\nfrom torch.utils.data import DataLoader, random_split\nimport torch.nn as nn\nimport torch.optim as optim\n# Transformations\ntransform = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Load dataset\ndata_dir = 'onevrest'\ndata_dir2='fiveclass'\nfrom sklearn.model_selection import KFold\nkfold = KFold(n_splits=3, shuffle=True, random_state=42)\n\nThis code implements K-fold cross-validation to train and evaluate an image classifier in PyTorch. After setting hyperparameters and defining the overall validation strategy, it loads the entire image dataset and applies pre-processing transformations. The core loop iterates through each fold defined by K-fold. Within each fold, the data is split into training and testing subsets. Separate data loaders are created for efficient batch processing during training and evaluation. A pre-trained model (ConvNext Tiny) is re-initialized for each fold to prevent overfitting, and its final layer is adjusted to match the number of classes in the dataset. The model is then trained on the designated training set using an Adam optimizer and cross-entropy loss function. During evaluation on the testing set, the model’s predictions are compared to true labels to calculate accuracy and a confusion matrix. This process is repeated for all folds. Finally, the code computes and prints the overall average accuracy and an average confusion matrix across all folds, providing a more comprehensive understanding of the model’s performance and potential biases.\nfrom sklearn.model_selection import KFold\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import models\nfrom torch import nn, optim\nimport torch\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\n\nnum_classes = 2 \nnum_epochs = 2\nbatch_size = 32\n\nn_splits = 3  # Number of folds\n\nfull_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\nkfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n\nall_acc = []\nall_conf_matrices = []\n\nfor fold, (train_idx, test_idx) in enumerate(kfold.split(full_dataset)):\n    # Splitting datasets per fold\n    train_subset = Subset(full_dataset, train_idx)\n    test_subset = Subset(full_dataset, test_idx)\n\n    # Data loaders for the current fold\n    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n    test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n\n    # Reinitialize model and optimizer\n    model = models.convnext_tiny(weights=None)\n    num_ftrs = model.classifier[2].in_features\n    model.classifier[2] = nn.Linear(num_ftrs, num_classes)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.CrossEntropyLoss()\n\n    # Training loop for current fold\n    for epoch in range(num_epochs):\n        model.train()\n        for i, (inputs, targets) in enumerate(train_loader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n\n    # Evaluation for current fold\n    model.eval()\n    y_true = []\n    y_pred = []\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(preds.cpu().numpy())\n\n    acc = (np.array(y_true) == np.array(y_pred)).mean()\n    all_acc.append(acc)\n    conf_matrix = confusion_matrix(y_true, y_pred)\n    all_conf_matrices.append(conf_matrix)\n    print(f'Fold {fold+1}, Test Accuracy: {acc:.4f}')\n\n# Average accuracy and confusion matrix\naverage_acc = np.mean(all_acc)\naverage_conf_matrix = np.mean(all_conf_matrices, axis=0)\nprint(f'Average Test Accuracy: {average_acc:.4f}')\nprint('Average Confusion Matrix:')\nprint(average_conf_matrix)\nFold 1, Test Accuracy: 0.9900\nFold 2, Test Accuracy: 0.9883\nFold 3, Test Accuracy: 0.9883\nAverage Test Accuracy: 0.9889\nAverage Confusion Matrix:\n[[   0.           20.        ]\n [   0.         1779.66666667]]",
    "crumbs": [
      "Animal Classifier"
    ]
  },
  {
    "objectID": "animal-classifier-ML.html#five-class-classification",
    "href": "animal-classifier-ML.html#five-class-classification",
    "title": "Animal Classifier",
    "section": "Five-Class Classification",
    "text": "Five-Class Classification\nThis code trains and evaluates an image classifier for a 5-class problem using K-fold cross-validation with PyTorch. It begins by showcasing the entire dataset using print(full_dataset), which might reveal details about the image classes and their distribution. K-fold cross-validation is then configured with three folds (n_splits=3) for a more robust evaluation. The core loop iterates through each fold, splitting the data into training and testing subsets using Subset. Separate data loaders are created for efficient handling of batches during training and evaluation.\nWithin each fold, a pre-trained ConvNext Tiny model with weights loaded from ImageNet (weights=‘IMAGENET1K_V1’) is used as a starting point. The final layer is adjusted to match the specific number of classes in the current dataset. The model is then trained on the designated training set with an Adam optimizer and cross-entropy loss function. During evaluation on the testing set, the model’s predictions are compared to true labels to calculate accuracy and a confusion matrix.\nThis process repeats for all folds. Finally, the code computes and prints the overall average accuracy and an average confusion matrix, providing a more comprehensive assessment of the model’s performance across the entire dataset.\nfrom sklearn.model_selection import KFold\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import models\nfrom torch import nn, optim\nimport torch\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\n\nnum_classes = 5  # Adjust this based on your dataset\nnum_epochs = 3\nbatch_size = 32\n\nn_splits = 3  # Number of folds\n\nfull_dataset = datasets.ImageFolder(root=data_dir2, transform=transform)\nprint(full_dataset)\n\nkfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n\nall_acc = []\nall_conf_matrices = []\n\nfor fold, (train_idx, test_idx) in enumerate(kfold.split(full_dataset)):\n    # Splitting datasets per fold\n    train_subset = Subset(full_dataset, train_idx)\n    test_subset = Subset(full_dataset, test_idx)\n\n    # Data loaders for the current fold\n    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n    test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n\n    # Reinitialize model and optimizer\n    model = models.convnext_tiny(weights='IMAGENET1K_V1')\n    num_ftrs = model.classifier[2].in_features\n    model.classifier[2] = nn.Linear(num_ftrs, num_classes)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.CrossEntropyLoss()\n\n    # Training loop for current fold\n    for epoch in range(num_epochs):\n        model.train()\n        for i, (inputs, targets) in enumerate(train_loader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n\n    # Evaluation for current fold\n    model.eval()\n    y_true = []\n    y_pred = []\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(preds.cpu().numpy())\n\n    acc = (np.array(y_true) == np.array(y_pred)).mean()\n    all_acc.append(acc)\n    conf_matrix = confusion_matrix(y_true, y_pred)\n    all_conf_matrices.append(conf_matrix)\n    print(f'Fold {fold+1}, Test Accuracy: {acc:.4f}')\n\n# Average accuracy and confusion matrix\naverage_acc = np.mean(all_acc)\naverage_conf_matrix = np.mean(all_conf_matrices, axis=0)\nprint(f'Average Test Accuracy: {average_acc:.4f}')\nprint('Average Confusion Matrix:')\nprint(average_conf_matrix)\nDataset ImageFolder\n    Number of datapoints: 5400\n    Root location: fiveclass\n    StandardTransform\nTransform: Compose(\n               RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=warn)\n               RandomHorizontalFlip(p=0.5)\n               ToTensor()\n               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n           )\nDownloading: \"https://download.pytorch.org/models/convnext_tiny-983f1562.pth\" to /root/.cache/torch/hub/checkpoints/convnext_tiny-983f1562.pth\n100%|██████████| 109M/109M [00:07&lt;00:00, 16.1MB/s] \nFold 1, Test Accuracy: 0.1950\nThis code defines a complex custom convolutional neural network (CNN) architecture named ComplexCustomCNN built using PyTorch. It inherits from the nn.Module class to create a trainable neural network. Upon initialization, it accepts the number of classes (num_classes) to predict, which determines the final output layer’s size. The network primarily relies on convolutional layers for feature extraction. These layers take an input image, apply filters (kernels) to learn patterns, and produce feature maps. Batch normalization layers are strategically placed after each convolutional layer to improve training stability. A pooling layer downsamples the feature maps after each convolutional block, reducing complexity and spatial dimensions. The network then transitions to fully-connected layers, where the learned features are processed for classification. The first fully-connected layer is adjusted based on the assumed input image size (224x224 in this case). Dropout layers with a 50% chance of dropping neurons are included after the first two fully-connected layers to prevent overfitting during training. Finally, the code shows an example of creating an instance of the ComplexCustomCNN model with a user-defined number of classes, and then it prints the model architecture for reference. This customizable CNN architecture can be a powerful tool for various image classification tasks, with the flexibility to adapt the number of layers, channels, and hyperparameters to fit the specific requirements of your dataset.\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass ComplexCustomCNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super(ComplexCustomCNN, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n        self.bn2 = nn.BatchNorm2d(128)\n        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n        self.bn3 = nn.BatchNorm2d(256)\n        self.conv4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n        self.bn4 = nn.BatchNorm2d(512)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.fc1 = nn.Linear(512 * 28 * 28, 1024)  # Adjusted for 224x224 input images\n        self.bn_fc1 = nn.BatchNorm1d(1024)\n        self.fc2 = nn.Linear(1024, 512)\n        self.bn_fc2 = nn.BatchNorm1d(512)\n        self.fc3 = nn.Linear(512, num_classes)\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n        x = x.view(-1, 512 * 28 * 28)  # Adjusted for 224x224 input images\n        x = self.dropout(F.relu(self.bn_fc1(self.fc1(x))))\n        x = self.dropout(F.relu(self.bn_fc2(self.fc2(x))))\n        x = self.fc3(x)\n        return x\n\n# Example usage\nnum_classes = 10  # Adjust based on your dataset\nmodel = ComplexCustomCNN(num_classes=num_classes)\nprint(model)\nComplexCustomCNN(\n  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=401408, out_features=1024, bias=True)\n  (bn_fc1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n  (bn_fc2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (fc3): Linear(in_features=512, out_features=10, bias=True)\n  (dropout): Dropout(p=0.5, inplace=False)\n)\nfrom sklearn.model_selection import KFold\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import datasets, transforms\nfrom torch import nn, optim\nimport torch\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\n\n\n\n# Define the transformation for the dataset\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\nnum_epochs = 10\nbatch_size = 32\nn_splits = 3\nnum_classes = 5\n\nfull_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\nkfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n\nall_acc = []\nall_conf_matrices = []\n\nfor fold, (train_idx, test_idx) in enumerate(kfold.split(full_dataset)):\n    train_subset = Subset(full_dataset, train_idx)\n    test_subset = Subset(full_dataset, test_idx)\n\n    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n    test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n\n    model = ComplexCustomCNN(num_classes=num_classes)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.CrossEntropyLoss()\n\n    for epoch in range(num_epochs):\n        model.train()\n        for i, (inputs, targets) in enumerate(train_loader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    y_true = []\n    y_pred = []\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(preds.cpu().numpy())\n\n    acc = (np.array(y_true) == np.array(y_pred)).mean()\n    all_acc.append(acc)\n    conf_matrix = confusion_matrix(y_true, y_pred)\n    all_conf_matrices.append(conf_matrix)\n    print(f'Fold {fold+1}, Test Accuracy: {acc:.4f}')\n\naverage_acc = np.mean(all_acc)\naverage_conf_matrix = np.mean(all_conf_matrices, axis=0)\nprint(f'Average Test Accuracy: {average_acc:.4f}')\nprint('Average Confusion Matrix:')\nprint(average_conf_matrix)",
    "crumbs": [
      "Animal Classifier"
    ]
  }
]